# ğŸš€ Slang Translator

A powerful AI-powered translator that converts formal English text to informal slang using the Mistral 7B model.

## âœ¨ Features

- **AI-Powered Translation**: Uses Mistral 7B Instruct model for accurate translations
- **Beautiful Web Interface**: Modern, responsive design
- **Real-time Translation**: Instant results as you type
- **Example Sentences**: Click to try pre-loaded examples
- **Health Monitoring**: Built-in health check endpoint

## ğŸš€ Quick Start

### Option 1: Web App (Recommended)
```bash
./run_web_app.sh
```
Then open http://localhost:5002 in your browser.

### Option 2: Command Line
```bash
source nlpenv/bin/activate
python Scriptss/infer.py
```

## ğŸ“ Project Structure

```
Slang_Translator/
â”œâ”€â”€ web_app/                 # Web application
â”‚   â”œâ”€â”€ app.py              # Main Flask app
â”‚   â”œâ”€â”€ templates/          # HTML templates
â”‚   â””â”€â”€ static/             # CSS/JS files
â”œâ”€â”€ Scriptss/               # Python scripts
â”‚   â”œâ”€â”€ infer.py            # Command-line inference
â”‚   â”œâ”€â”€ fine_tune.py        # Model training
â”‚   â”œâ”€â”€ preprocess_data.py  # Data preprocessing
â”‚   â””â”€â”€ format_data.py      # Data formatting
â”œâ”€â”€ Dataa/                  # Data files
â”‚   â”œâ”€â”€ raw_data_fixed.csv  # Cleaned dataset
â”‚   â””â”€â”€ formatted_dataset.jsonl # Training data
â””â”€â”€ run_web_app.sh         # Quick launcher
```

## ğŸ”§ Setup

1. **Activate virtual environment:**
   ```bash
   source nlpenv/bin/activate
   ```

2. **Install dependencies:**
   ```bash
   pip install -r web_app/requirements.txt
   ```

3. **Run the app:**
   ```bash
   ./run_web_app.sh
   ```

## ğŸŒ Web Interface

- **URL**: http://localhost:5002
- **Features**: 
  - Real-time translation
  - Example sentences
  - Responsive design
  - Error handling

## ğŸ“Š Data

- **Dataset**: 1,348 formal-to-informal text pairs
- **Format**: CSV with cleaned data
- **Training**: Ready for fine-tuning with Mistral 7B

## ğŸ” Authentication

- **Hugging Face Token**: Embedded in code
- **Model Access**: Automatic authentication
- **No Manual Setup**: Ready to use out of the box

## ğŸ³ Docker Deployment

### Quick Start with Docker
```bash
# Set your Hugging Face token
export HUGGINGFACE_HUB_TOKEN="your_token_here"

# Build and run with Docker
./build_docker.sh
```

### Manual Docker Commands
```bash
# Build the image
docker build -t slang-translator:latest .

# Run the container
docker run -d --name slang-translator-app -p 5000:5000 -e HUGGINGFACE_HUB_TOKEN="your_token" slang-translator:latest
```

### Access the App
- **Local URL**: http://localhost:5000
- **Health Check**: http://localhost:5000/health

## ğŸ¬ Demo Video

**Watch the live demo**: [Demo Video Link] (Coming Soon)

The demo shows:
- Docker containerization
- Web interface with "Created by Ayush Chaudhary"
- Real-time translation examples
- Technical implementation details

## ğŸš€ Deployment

### Local Development
```bash
./run_web_app.sh
```

### Docker (Recommended)
```bash
./build_docker.sh
```

## ğŸ› ï¸ Troubleshooting

- **Port 5002 in use**: The script automatically uses port 5002
- **Model loading slow**: First run downloads 13GB model
- **Memory issues**: Mistral 7B needs ~16GB RAM

## ğŸ“± Usage

1. **Web App**: Enter formal text â†’ Get slang translation
2. **CLI**: Run `python Scriptss/infer.py` for command-line interface
3. **API**: Use `/translate` endpoint for programmatic access

## ğŸ¯ Examples

- "I would like to request your assistance" â†’ "Can you help me out?"
- "Please wait a moment" â†’ "Hang on a sec"
- "Thank you for your help" â†’ "Thanks a lot!"

## ğŸ“ˆ Performance

- **Model**: Mistral 7B Instruct v0.2
- **Size**: ~13GB
- **Speed**: 2-5 seconds per translation
- **Accuracy**: High-quality slang translations

---

**Ready to translate? Run `./run_web_app.sh` and start converting formal text to slang!** ğŸ‰

made a new branch "test_new_changes"